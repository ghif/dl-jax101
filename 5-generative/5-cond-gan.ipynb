{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Conditional Generative Adversarial Network (cGAN) dengan JAX/Flax\n",
                "\n",
                "Notebook ini mendemonstrasikan implementasi **Conditional Generative Adversarial Network (cGAN)** menggunakan framework **JAX** dan library **Flax (NNX)**. Kita akan melatih model ini pada dataset **CIFAR-10** untuk menghasilkan gambar berdasarkan label kelas tertentu."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Perbedaan antara Conditional GAN (cGAN) dan DCGAN\n",
                "\n",
                "Penting untuk memahami perbedaan mendasar antara model cGAN yang kita buat ini dengan model **DCGAN (Deep Convolutional GAN)** yang mungkin sudah Anda pelajari sebelumnya:\n",
                "\n",
                "| Fitur | DCGAN | Conditional GAN (cGAN) |\n",
                "|---|---|---|\n",
                "| **Input Generator** | Hanya noise acak ($z$). | Noise acak ($z$) DAN informasi tambahan (misalnya label kelas $y$). |\n",
                "| **Input Discriminator** | Hanya gambar ($x$, baik asli maupun palsu). | Gambar ($x$) DAN informasi tambahan (label kelas $y$). |\n",
                "| **Kontrol Output** | Tidak ada kontrol langsung. Generator membuat gambar apa saja dari distribusi data. | Kita bisa mengontrol kelas gambar yang ingin dihasilkan (misal: \"buatkan saya gambar kucing\"). |\n",
                "| **Struktur Data** | Proses training bersifat *unsupervised* atau *self-supervised*. | Proses training memerlukan label (*supervised*) untuk mengkondisikan model. |\n",
                "\n",
                "**Intinya:**\n",
                "- **DCGAN** berfokus pada penggunaan arsitektur *Convolutional* untuk stabilitas training, tetapi ia menghasilkan gambar secara acak.\n",
                "- **cGAN** menambahkan mekanisme \"pengkondisian\" (conditioning) yang memungkinkan kita memandu proses pembangkitan gambar dengan memberikan label sebagai input tambahan baik pada Generator maupun Discriminator."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Persiapan Lingkungan dan Import\n",
                "\n",
                "Pertama, kita siapkan library yang dibutuhkan."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "JAX Device: [CpuDevice(id=0)]\n"
                    ]
                }
            ],
            "source": [
                "import jax\n",
                "import jax.numpy as jnp\n",
                "from flax import nnx\n",
                "import matplotlib.pyplot as plt\n",
                "import sys, os\n",
                "import numpy as np\n",
                "import time as timer\n",
                "from tqdm import tqdm\n",
                "import grain.python as grain\n",
                "import optax\n",
                "import urllib.request\n",
                "import tarfile\n",
                "import pickle\n",
                "\n",
                "# Konfigurasi path untuk utils (jika dijalankan di struktur folder dl-jax101)\n",
                "parent_dir = os.path.abspath(\"..\")\n",
                "if parent_dir not in sys.path:\n",
                "    sys.path.append(parent_dir)\n",
                "\n",
                "import viz_utils as vu\n",
                "import model_utils as mu\n",
                "\n",
                "print(f\"JAX Device: {jax.devices()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Hyperparameters dan Direktori\n",
                "\n",
                "Kita definisikan konstanta yang akan digunakan selama eksperimen."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "DATA_DIR = os.path.join(parent_dir, \"data\")\n",
                "MODEL_DIR = os.path.join(parent_dir, \"models\") \n",
                "\n",
                "BATCH_SIZE = 64\n",
                "NUM_EPOCH = 50\n",
                "IMAGE_SIZE = 64\n",
                "NC = 3        # Channel warna RGB\n",
                "NZ = 100      # Dimensi latent vector (noise)\n",
                "NGF = 64      # Generator feature size\n",
                "NDF = 64      # Discriminator feature size\n",
                "LR = 2e-4 \n",
                "BETA1 = 0.5 \n",
                "NVIZ = 64     # Jumlah sampel untuk visualisasi\n",
                "NUM_CLASSES = 10\n",
                "\n",
                "DATASET = 'cifar10'\n",
                "checkpoint_dir = os.path.join(MODEL_DIR, f\"cond-gan_{DATASET}_z{NZ}\")\n",
                "sample_dir = os.path.join(checkpoint_dir, \"samples\")\n",
                "\n",
                "for d in [checkpoint_dir, sample_dir, DATA_DIR]:\n",
                "    if not os.path.exists(d):\n",
                "        os.makedirs(d)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Dataset: CIFAR-10\n",
                "\n",
                "Fungsi-fungsi di bawah ini digunakan untuk mengunduh dan memuat dataset CIFAR-10 secara lokal."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading dataset...\n",
                        "Data loaded: (50000, 3072) images.\n"
                    ]
                }
            ],
            "source": [
                "def download_and_extract_cifar10(dest_dir):\n",
                "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
                "    filename = os.path.join(dest_dir, \"cifar-10-python.tar.gz\")\n",
                "    extract_path = os.path.join(dest_dir, \"cifar-10-batches-py\")\n",
                "    \n",
                "    if not os.path.exists(extract_path):\n",
                "        if not os.path.exists(filename):\n",
                "            print(f\"Downloading {url}...\")\n",
                "            urllib.request.urlretrieve(url, filename)\n",
                "        \n",
                "        with tarfile.open(filename, \"r:gz\") as tar:\n",
                "            tar.extractall(path=dest_dir)\n",
                "    return extract_path\n",
                "\n",
                "def load_cifar10_local(data_dir):\n",
                "    def unpickle(file):\n",
                "        with open(file, 'rb') as fo:\n",
                "            d = pickle.load(fo, encoding='bytes')\n",
                "        return d\n",
                "\n",
                "    images, labels = [], []\n",
                "    for i in range(1, 6):\n",
                "        batch = unpickle(os.path.join(data_dir, f\"data_batch_{i}\"))\n",
                "        images.append(batch[b'data'])\n",
                "        labels.append(batch[b'labels'])\n",
                "    \n",
                "    X_train = np.vstack(images)\n",
                "    y_train = np.hstack(labels).astype(np.int32)\n",
                "    return X_train, y_train\n",
                "\n",
                "print(\"Loading dataset...\")\n",
                "cifar_path = download_and_extract_cifar10(DATA_DIR)\n",
                "X_train_all, y_train_all = load_cifar10_local(cifar_path)\n",
                "print(f\"Data loaded: {X_train_all.shape} images.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Pipeline Data dengan Google Grain\n",
                "\n",
                "Kita gunakan Grain untuk melakukan batching dan preprocessing gambar (resizing ke 64x64 dan normalisasi ke range [-1, 1])."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CIFARSource(grain.RandomAccessDataSource):\n",
                "    def __init__(self, images, labels):\n",
                "        self._images = images\n",
                "        self._labels = labels\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self._images)\n",
                "        \n",
                "    def __getitem__(self, index):\n",
                "        from PIL import Image\n",
                "        # CIFAR-10 raw (3, 32, 32) -> (32, 32, 3)\n",
                "        img = self._images[index].reshape(3, 32, 32).transpose(1, 2, 0).astype(np.uint8)\n",
                "        img = Image.fromarray(img).resize((IMAGE_SIZE, IMAGE_SIZE), Image.BILINEAR)\n",
                "        img = np.array(img).astype(np.float32)\n",
                "        # Normalize to [-1, 1]\n",
                "        image = (img / 255.0) * 2.0 - 1.0\n",
                "        return {'image': image, 'label': self._labels[index]}\n",
                "\n",
                "def create_loader(data_source, batch_size, shuffle=False, seed=0):\n",
                "    sampler = grain.IndexSampler(\n",
                "        num_records=len(data_source),\n",
                "        shard_options=grain.NoSharding(),\n",
                "        shuffle=shuffle,\n",
                "        num_epochs=1,\n",
                "        seed=seed,\n",
                "    )\n",
                "    dataloader = grain.DataLoader(data_source=data_source, sampler=sampler, worker_count=0)\n",
                "    \n",
                "    class BatchIterator:\n",
                "        def __init__(self, loader, batch_size, num_records):\n",
                "            self.loader = loader\n",
                "            self.batch_size = batch_size\n",
                "            self.num_records = num_records\n",
                "        def __len__(self):\n",
                "            return (self.num_records + self.batch_size - 1) // self.batch_size\n",
                "        def __iter__(self):\n",
                "            batch_images, batch_labels = [], []\n",
                "            for record in self.loader:\n",
                "                batch_images.append(record['image'])\n",
                "                batch_labels.append(record['label'])\n",
                "                if len(batch_images) == self.batch_size:\n",
                "                    yield np.stack(batch_images), np.array(batch_labels)\n",
                "                    batch_images, batch_labels = [], []\n",
                "            if batch_images:\n",
                "                 yield np.stack(batch_images), np.array(batch_labels)\n",
                "    return BatchIterator(dataloader, batch_size, len(data_source))\n",
                "\n",
                "train_loader = create_loader(CIFARSource(X_train_all, y_train_all), BATCH_SIZE, shuffle=True, seed=42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Arsitektur Model\n",
                "\n",
                "### Generator\n",
                "Generator menerima noise acak dan label kelas (one-hot encoded) dan menghasilkan gambar. Di sini, label digabungkan (*concatenate*) dengan noise latent sebelum masuk ke lapisan konvolusi."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Generator(nnx.Module):\n",
                "    def __init__(self, nz, ngf, nc, num_classes, rngs: nnx.Rngs):\n",
                "        normal_init = nnx.initializers.normal(0.02)\n",
                "        self.num_classes = num_classes\n",
                "        \n",
                "        # Input ke convt1: (N, 1, 1, nz + num_classes)\n",
                "        self.convt1 = nnx.ConvTranspose(nz + num_classes, ngf * 8, kernel_size=(4, 4), strides=(1, 1), padding='VALID', \n",
                "                                        use_bias=False, rngs=rngs, kernel_init=normal_init)\n",
                "        self.bn1 = nnx.BatchNorm(ngf * 8, rngs=rngs)\n",
                "        \n",
                "        self.convt2 = nnx.ConvTranspose(ngf * 8, ngf * 4, kernel_size=(4, 4), strides=(2, 2), padding='SAME', \n",
                "                                        use_bias=False, rngs=rngs, kernel_init=normal_init)\n",
                "        self.bn2 = nnx.BatchNorm(ngf * 4, rngs=rngs)\n",
                "        \n",
                "        self.convt3 = nnx.ConvTranspose(ngf * 4, ngf * 2, kernel_size=(4, 4), strides=(2, 2), padding='SAME', \n",
                "                                        use_bias=False, rngs=rngs, kernel_init=normal_init)\n",
                "        self.bn3 = nnx.BatchNorm(ngf * 2, rngs=rngs)\n",
                "\n",
                "        self.convt4 = nnx.ConvTranspose(ngf * 2, ngf, kernel_size=(4, 4), strides=(2, 2), padding='SAME', \n",
                "                                        use_bias=False, rngs=rngs, kernel_init=normal_init)\n",
                "        self.bn4 = nnx.BatchNorm(ngf, rngs=rngs)\n",
                "        \n",
                "        self.convt5 = nnx.ConvTranspose(ngf, nc, kernel_size=(4, 4), strides=(2, 2), padding='SAME', \n",
                "                                        use_bias=False, rngs=rngs, kernel_init=normal_init)\n",
                "\n",
                "    def __call__(self, z, c, train: bool = True, use_running_average: bool = None):\n",
                "        if use_running_average is None: use_running_average = not train\n",
                "        \n",
                "        # z: (N, NZ), c: (N, num_classes)\n",
                "        # Concatenate noise dan label\n",
                "        h = jnp.concatenate([z, c], axis=1)\n",
                "        h = h.reshape(h.shape[0], 1, 1, -1)\n",
                "        \n",
                "        h = nnx.relu(self.bn1(self.convt1(h), use_running_average=use_running_average))\n",
                "        h = nnx.relu(self.bn2(self.convt2(h), use_running_average=use_running_average))\n",
                "        h = nnx.relu(self.bn3(self.convt3(h), use_running_average=use_running_average))\n",
                "        h = nnx.relu(self.bn4(self.convt4(h), use_running_average=use_running_average))\n",
                "        return nnx.tanh(self.convt5(h))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Discriminator\n",
                "Discriminator menerima gambar dan label kelas. Label dalam bentuk one-hot diputar (*broadcast*) sehingga memiliki dimensi spasial yang sama dengan gambar (misal 64x64), lalu digabungkan sebagai channel tambahan."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Discriminator(nnx.Module):\n",
                "    def __init__(self, nc, ndf, num_classes, rngs: nnx.Rngs):\n",
                "        normal_init = nnx.initializers.normal(0.02)\n",
                "        \n",
                "        # Input ke conv1: (N, 64, 64, nc + num_classes)\n",
                "        self.conv1 = nnx.Conv(nc + num_classes, ndf, kernel_size=(4, 4), strides=(2, 2), padding='SAME', \n",
                "                              use_bias=False, rngs=rngs, kernel_init=normal_init)\n",
                "        self.conv2 = nnx.Conv(ndf, ndf * 2, kernel_size=(4, 4), strides=(2, 2), padding='SAME', \n",
                "                              use_bias=False, rngs=rngs, kernel_init=normal_init)\n",
                "        self.bn2 = nnx.BatchNorm(ndf * 2, rngs=rngs)\n",
                "        self.conv3 = nnx.Conv(ndf * 2, ndf * 4, kernel_size=(4, 4), strides=(2, 2), padding='SAME', \n",
                "                              use_bias=False, rngs=rngs, kernel_init=normal_init)\n",
                "        self.bn3 = nnx.BatchNorm(ndf * 4, rngs=rngs)\n",
                "        self.conv4 = nnx.Conv(ndf * 4, ndf * 8, kernel_size=(4, 4), strides=(2, 2), padding='SAME', \n",
                "                              use_bias=False, rngs=rngs, kernel_init=normal_init)\n",
                "        self.bn4 = nnx.BatchNorm(ndf * 8, rngs=rngs)\n",
                "        self.conv5 = nnx.Conv(ndf * 8, 1, kernel_size=(4, 4), strides=(1, 1), padding='VALID', \n",
                "                              use_bias=False, rngs=rngs, kernel_init=normal_init)\n",
                "\n",
                "    def __call__(self, x, c, train: bool = True, use_running_average: bool = None):\n",
                "        if use_running_average is None: use_running_average = not train\n",
                "            \n",
                "        # x: (N, 64, 64, 3), c: (N, 10)\n",
                "        # Broadcast c (label) ke dimensi spasial\n",
                "        c_spatial = jnp.broadcast_to(c[:, None, None, :], (x.shape[0], x.shape[1], x.shape[2], c.shape[1]))\n",
                "        h = jnp.concatenate([x, c_spatial], axis=-1)\n",
                "        \n",
                "        h = nnx.leaky_relu(self.conv1(h), negative_slope=0.2)\n",
                "        h = nnx.leaky_relu(self.bn2(self.conv2(h), use_running_average=use_running_average), negative_slope=0.2)\n",
                "        h = nnx.leaky_relu(self.bn3(self.conv3(h), use_running_average=use_running_average), negative_slope=0.2)\n",
                "        h = nnx.leaky_relu(self.bn4(self.conv4(h), use_running_average=use_running_average), negative_slope=0.2)\n",
                "        return self.conv5(h).flatten()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Logic Training\n",
                "\n",
                "Pembungkus model CGAN, optimizer, dan fungsi loss."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CGAN(nnx.Module):\n",
                "    def __init__(self, nz, ngf, nc, ndf, num_classes, rngs: nnx.Rngs):\n",
                "        self.netG = Generator(nz, ngf, nc, num_classes, rngs)\n",
                "        self.netD = Discriminator(nc, ndf, num_classes, rngs)\n",
                "\n",
                "# Inisialisasi Model, RNGs dan Optimizer\n",
                "rngs = nnx.Rngs(0)\n",
                "model = CGAN(NZ, NGF, NC, NDF, NUM_CLASSES, rngs=rngs)\n",
                "optimizerG = nnx.Optimizer(model.netG, optax.adam(LR, b1=BETA1), wrt=nnx.Param)\n",
                "optimizerD = nnx.Optimizer(model.netD, optax.adam(LR, b1=BETA1), wrt=nnx.Param)\n",
                "\n",
                "def loss_bce(logits, labels):\n",
                "    return jnp.mean(optax.sigmoid_binary_cross_entropy(logits, labels))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Fungsi Step Training\n",
                "\n",
                "Kita membagi training menjadi dua langkah: `train_step_D` untuk Discriminator dan `train_step_G` untuk Generator."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "@nnx.jit\n",
                "def train_step_D(model, optimizerD, real_x, c_vec, noise):\n",
                "    # Hasil generate dari G (detach/stop_gradient karena kita hanya update D)\n",
                "    fake_x = model.netG(noise, c_vec, train=True)\n",
                "    fake_x = jax.lax.stop_gradient(fake_x)\n",
                "    \n",
                "    def loss_fn(model):\n",
                "        real_logits = model.netD(real_x, c_vec, train=True)\n",
                "        fake_logits = model.netD(fake_x, c_vec, train=True)\n",
                "        \n",
                "        errD_real = loss_bce(real_logits, jnp.ones_like(real_logits))\n",
                "        errD_fake = loss_bce(fake_logits, jnp.zeros_like(fake_logits))\n",
                "        return errD_real + errD_fake, (nnx.sigmoid(real_logits), nnx.sigmoid(fake_logits))\n",
                "        \n",
                "    (loss, (real_p, fake_p)), grads = nnx.value_and_grad(loss_fn, has_aux=True)(model)\n",
                "    optimizerD.update(model.netD, grads.netD)\n",
                "    return loss, jnp.mean(real_p), jnp.mean(fake_p)\n",
                "\n",
                "@nnx.jit\n",
                "def train_step_G(model, optimizerG, c_vec, noise):\n",
                "    def loss_fn(model):\n",
                "        fake_x = model.netG(noise, c_vec, train=True)\n",
                "        fake_logits = model.netD(fake_x, c_vec, train=True)\n",
                "        # Generator ingin Discriminator mengira gambar palsu ini real (label=1)\n",
                "        errG = loss_bce(fake_logits, jnp.ones_like(fake_logits))\n",
                "        return errG, nnx.sigmoid(fake_logits)\n",
                "        \n",
                "    (loss, outD), grads = nnx.value_and_grad(loss_fn, has_aux=True)(model)\n",
                "    optimizerG.update(model.netG, grads.netG)\n",
                "    return loss, jnp.mean(outD)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Loop Pelatihan (Main Loop)\n",
                "\n",
                "Sekarang kita jalankan proses pelatihannya. Di setiap epoch, kita akan mengambil noise yang tetap (`fixed_latent`) dan label yang tetap (`fixed_cvec`) untuk memantau perkembangan Generator."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting Training Loop...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1:   7%|â–‹         | 57/782 [05:11<1:06:05,  5.47s/batch, Dgz=0.0005, Dx=0.9543, Loss_D=0.2194, Loss_G=8.7065] \n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m c_vec = jax.nn.one_hot(y, NUM_CLASSES)\n\u001b[32m     16\u001b[39m step_rng, rng_d, rng_g = jax.random.split(step_rng, \u001b[32m3\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m noise_d = \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNZ\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m errD, D_x, D_G_z1 = train_step_D(model, optimizerD, real_x, c_vec, noise_d)\n\u001b[32m     20\u001b[39m noise_g = jax.random.normal(rng_g, (batch_size, NZ))\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Work/Installer/miniconda3/envs/jax-cpu/lib/python3.11/site-packages/jax/_src/random.py:851\u001b[39m, in \u001b[36mnormal\u001b[39m\u001b[34m(key, shape, dtype, out_sharding)\u001b[39m\n\u001b[32m    848\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtypes.issubdtype(dtype, np.inexact):\n\u001b[32m    849\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdtype argument to `normal` must be a float or complex dtype, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    850\u001b[39m                    \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m851\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmaybe_auto_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_normal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_sharding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[31mKeyboardInterrupt\u001b[39m: "
                    ]
                }
            ],
            "source": [
                "print(\"Starting Training Loop...\")\n",
                "step_rng = jax.random.PRNGKey(0)\n",
                "\n",
                "# Noise tetap untuk evaluasi visual\n",
                "fixed_latent = jax.random.normal(jax.random.PRNGKey(42), (NVIZ, NZ))\n",
                "fixed_y = jnp.array([i % NUM_CLASSES for i in range(NVIZ)])\n",
                "fixed_cvec = jax.nn.one_hot(fixed_y, NUM_CLASSES)\n",
                "\n",
                "for epoch in range(NUM_EPOCH):\n",
                "    start_t = timer.time()\n",
                "    with tqdm(train_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}\") as tepoch:\n",
                "        for batch_idx, (real_x, y) in enumerate(tepoch):\n",
                "            batch_size = real_x.shape[0]\n",
                "            c_vec = jax.nn.one_hot(y, NUM_CLASSES)\n",
                "            \n",
                "            step_rng, rng_d, rng_g = jax.random.split(step_rng, 3)\n",
                "            noise_d = jax.random.normal(rng_d, (batch_size, NZ))\n",
                "            errD, D_x, D_G_z1 = train_step_D(model, optimizerD, real_x, c_vec, noise_d)\n",
                "            \n",
                "            noise_g = jax.random.normal(rng_g, (batch_size, NZ))\n",
                "            errG, D_G_z2 = train_step_G(model, optimizerG, c_vec, noise_g)\n",
                "            \n",
                "            if batch_idx % 10 == 0:\n",
                "                tepoch.set_postfix(Loss_D=f\"{errD:.4f}\", Loss_G=f\"{errG:.4f}\", Dx=f\"{D_x:.4f}\", Dgz=f\"{D_G_z2:.4f}\")\n",
                "\n",
                "    # Visualisasi hasil setiap epoch\n",
                "    fake_samples = model.netG(fixed_latent, fixed_cvec, train=False)\n",
                "    grid = vu.set_grid(fake_samples, num_cells=NVIZ)\n",
                "    plt.figure(figsize=(8, 8))\n",
                "    plt.imshow(np.transpose(np.array(vu.normalize(grid, 0, 1)), (1, 2, 0)))\n",
                "    \n",
                "    plt.title(f\"Generated Samples Epoch {epoch+1}\")\n",
                "    plt.axis('off')\n",
                "    plt.savefig(os.path.join(sample_dir, f'samples_epoch_{epoch+1}.png'))\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "jax-cpu",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
